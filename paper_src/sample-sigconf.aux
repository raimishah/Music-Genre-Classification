\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{Pachet:2003}
\citation{GTZAN:2002}
\citation{KNN:2009}
\citation{Clustering:2001}
\citation{SVM:2006}
\citation{Pachet:2003}
\citation{PyTorch:2017}
\citation{MFCC:2011}
\providecommand \oddpage@label [2]{}
\@writefile{toc}{\contentsline {section}{Abstract}{1}{section*.1}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\citation{GTZAN:2002}
\citation{GTZAN:2002}
\citation{Pachet:2003}
\citation{Feng:2016}
\citation{Xing:2016}
\citation{Xing:2016}
\citation{Chun:2010}
\citation{Smaragdis:2002}
\citation{Chun:2010}
\citation{MFCC:2011}
\@writefile{toc}{\contentsline {section}{\numberline {2}Related Work}{2}{section.2}}
\newlabel{sec:related}{{2}{2}{Related Work}{section.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces  Mel-spectrogram of classical genre. \relax }}{2}{figure.caption.4}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:big_picture1}{{1}{2}{Mel-spectrogram of classical genre. \relax }{figure.caption.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Proposed Approach}{2}{section.3}}
\newlabel{sec:approach}{{3}{2}{Proposed Approach}{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Musical Dataset}{2}{subsection.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Feature Extraction: Mel Frequency Cepstral Coefficients (MFCC)}{2}{subsection.3.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Dimensionality Reduction with Principal Component Analysis (PCA)}{2}{subsection.3.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces  Mel-spectrogram of metal genre. \relax }}{3}{figure.caption.5}}
\newlabel{fig:big_picture2}{{2}{3}{Mel-spectrogram of metal genre. \relax }{figure.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces  Mel-spectrogram of pop genre. \relax }}{3}{figure.caption.6}}
\newlabel{fig:big_picture3}{{3}{3}{Mel-spectrogram of pop genre. \relax }{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces  Mel-spectrogram of country genre. \relax }}{3}{figure.caption.7}}
\newlabel{fig:big_picture4}{{4}{3}{Mel-spectrogram of country genre. \relax }{figure.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces  Mel-spectrogram of blues genre. \relax }}{3}{figure.caption.8}}
\newlabel{fig:big_picture5}{{5}{3}{Mel-spectrogram of blues genre. \relax }{figure.caption.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces  Norms of eigenvectors of our data plotted with respect to PCA dimensions. Note that we only want to keep the most significant components. \relax }}{3}{figure.caption.9}}
\newlabel{fig:big_picture5}{{6}{3}{Norms of eigenvectors of our data plotted with respect to PCA dimensions. Note that we only want to keep the most significant components. \relax }{figure.caption.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces  2-dimensional scatter plot of our data with different genres. \relax }}{3}{figure.caption.10}}
\newlabel{fig:big_picture5}{{7}{3}{2-dimensional scatter plot of our data with different genres. \relax }{figure.caption.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Machine Learning Algorithms}{3}{subsection.3.4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.1}\textbf  {K-Nearest Neighbor (K-NN)}}{3}{subsubsection.3.4.1}}
\citation{SVM:2006}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces  3-dimensional scatter plot of our data with different genres. \relax }}{4}{figure.caption.11}}
\newlabel{fig:big_picture5}{{8}{4}{3-dimensional scatter plot of our data with different genres. \relax }{figure.caption.11}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.2}\textbf  {Support Vector Machines (SVM)}}{4}{subsubsection.3.4.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.3}\textbf  {K-Means Clustering}}{4}{subsubsection.3.4.3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.4}\textbf  {Gaussian Mixture Models (GMM)}}{4}{subsubsection.3.4.4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.5}\textbf  {Simple 3-layer Neural Network}}{4}{subsubsection.3.4.5}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.6}\textbf  {Convolutional Neural Network (CNN)}}{4}{subsubsection.3.4.6}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces  A summary of our final architecture of 3-layer Neural Network. \relax }}{4}{figure.caption.12}}
\newlabel{fig:big_picture1}{{9}{4}{A summary of our final architecture of 3-layer Neural Network. \relax }{figure.caption.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces  A summary of our final architecture of Convolutional Neural Network. \relax }}{4}{figure.caption.13}}
\newlabel{fig:big_picture1}{{10}{4}{A summary of our final architecture of Convolutional Neural Network. \relax }{figure.caption.13}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.7}\textbf  {Super-Classifier (SC)}}{4}{subsubsection.3.4.7}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Experimental Results}{4}{section.4}}
\newlabel{sec:results}{{4}{4}{Experimental Results}{section.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Experiment Setup}{4}{subsection.4.1}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Classification results of each classifier\relax }}{5}{table.caption.14}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces  Confusion matrix for k-Nearest Neighbors. \relax }}{5}{figure.caption.15}}
\newlabel{fig:big_picture5}{{11}{5}{Confusion matrix for k-Nearest Neighbors. \relax }{figure.caption.15}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Classification Accuracy}{5}{subsection.4.2}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Conclusion}{5}{section.5}}
\newlabel{sec:conclusion}{{5}{5}{Conclusion}{section.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces  Confusion matrix for Support Vector Machines. \relax }}{5}{figure.caption.16}}
\newlabel{fig:big_picture5}{{12}{5}{Confusion matrix for Support Vector Machines. \relax }{figure.caption.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces  Confusion matrix for K-Means Clustering. \relax }}{5}{figure.caption.17}}
\newlabel{fig:big_picture5}{{13}{5}{Confusion matrix for K-Means Clustering. \relax }{figure.caption.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces  Confusion matrix for Gaussian Mixture Models. \relax }}{5}{figure.caption.18}}
\newlabel{fig:big_picture5}{{14}{5}{Confusion matrix for Gaussian Mixture Models. \relax }{figure.caption.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces  Confusion matrix for 3-layer Neural Network. \relax }}{5}{figure.caption.19}}
\newlabel{fig:big_picture5}{{15}{5}{Confusion matrix for 3-layer Neural Network. \relax }{figure.caption.19}{}}
\bibstyle{ACM-Reference-Format}
\bibdata{IEEEabrv,IEEEexample}
\bibcite{Pachet:2003}{{1}{2003}{{Aucouturier}}{{Aucouturier}}}
\bibcite{Feng:2016}{{2}{2016}{{Feng}}{{Feng}}}
\bibcite{MFCC:2011}{{3}{2011}{{Fu et~al\unhbox \voidb@x \hbox {.}}}{{Fu, Lu, Ting, and Zhang}}}
\bibcite{Chun:2010}{{4}{2010}{{Li et~al\unhbox \voidb@x \hbox {.}}}{{Li, Chan, and Chun}}}
\bibcite{SVM:2006}{{5}{2006}{{Mandel et~al\unhbox \voidb@x \hbox {.}}}{{Mandel, Poliner, and Ellis}}}
\bibcite{PyTorch:2017}{{6}{2017}{{Paszke et~al\unhbox \voidb@x \hbox {.}}}{{Paszke, Gross, Chintala, Chanan, Yang, DeVito, Lin, Desmaison, Antiga, and Lerer}}}
\bibcite{KNN:2009}{{7}{2009}{{Peterson}}{{Peterson}}}
\bibcite{GTZAN:2002}{{8}{2002}{{Tzanetakis and Cook}}{{Tzanetakis and Cook}}}
\bibcite{Clustering:2001}{{9}{2001}{{Wagstaff et~al\unhbox \voidb@x \hbox {.}}}{{Wagstaff, Cardie, Rogers, and Schr\"{o}dl}}}
\bibcite{Smaragdis:2002}{{10}{2002}{{Whitman and Smaragdis}}{{Whitman and Smaragdis}}}
\bibcite{Xing:2016}{{11}{2016}{{Zhang et~al\unhbox \voidb@x \hbox {.}}}{{Zhang, Lei, Xu, and Xing}}}
\newlabel{tocindent-1}{0pt}
\newlabel{tocindent0}{0pt}
\newlabel{tocindent1}{4.185pt}
\newlabel{tocindent2}{10.34999pt}
\newlabel{tocindent3}{18.198pt}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces  Confusion matrix for Convolutional Neural Network. \relax }}{6}{figure.caption.20}}
\newlabel{fig:big_picture5}{{16}{6}{Confusion matrix for Convolutional Neural Network. \relax }{figure.caption.20}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces  Confusion matrix for Super Classifier. \relax }}{6}{figure.caption.21}}
\newlabel{fig:big_picture5}{{17}{6}{Confusion matrix for Super Classifier. \relax }{figure.caption.21}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces  Training loss vs. number of epochs for 3-layer neural network. \relax }}{6}{figure.caption.22}}
\newlabel{fig:big_picture5}{{18}{6}{Training loss vs. number of epochs for 3-layer neural network. \relax }{figure.caption.22}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces  Training loss vs. number of epochs for Convolutional Neural Network. \relax }}{6}{figure.caption.23}}
\newlabel{fig:big_picture5}{{19}{6}{Training loss vs. number of epochs for Convolutional Neural Network. \relax }{figure.caption.23}{}}
\@writefile{toc}{\contentsline {section}{References}{6}{section*.25}}
\newlabel{TotPages}{{6}{6}{}{page.6}{}}
